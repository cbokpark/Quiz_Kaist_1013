{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Seq2Seq_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egj3dR_lfo4L",
        "colab_type": "text"
      },
      "source": [
        "### 필요 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRHh7PXAfo4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To ignore deprecated warnings\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "warnings.warn(\"deprecated\", DeprecationWarning)\n",
        "\n",
        "import torch # torch library \n",
        "import torch.nn as nn # Nueral Network에 대한 package\n",
        "import numpy as np  # numpy \n",
        "import editdistance # 평가 지표로서 사용될 edit distance \n",
        "import matplotlib.pyplot as plt # plot 을 찍기 위한 라이브러리\n",
        "import tqdm\n",
        "import torch.nn.functional as F # pytorch function 들을 사용하기 위한 용도 \n",
        "from torch.utils import data # dataset 관련된 utility 를 사용하려는 용도\n",
        "from random import choice, randrange # random\n",
        "from itertools import zip_longest \n",
        "import librosa\n",
        "import os   # directory 생성 및 디렉토리 생성과 관련된 package \n",
        "import json \n",
        "import random\n",
        "import subprocess\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHl99JeGfo4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch(iterable, n=1):\n",
        "    args = [iter(iterable)] * n\n",
        "    return zip_longest(*args)\n",
        "\n",
        "\n",
        "def pad_tensor(vec, pad, value=0, dim=0):\n",
        "    \"\"\"\n",
        "    pad token으로 채우는 용도 \n",
        "    args:\n",
        "        vec - tensor to pad\n",
        "        pad - the size to pad to\n",
        "        dim - dimension to pad\n",
        "    return:\n",
        "        a new tensor padded to 'pad' in dimension 'dim'\n",
        "    \"\"\"\n",
        "    pad_size = pad - vec.shape[0]\n",
        "\n",
        "    if len(vec.shape) == 2:\n",
        "        zeros = torch.ones((pad_size, vec.shape[-1])) * value\n",
        "    elif len(vec.shape) == 1:\n",
        "        zeros = torch.ones((pad_size,)) * value\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return torch.cat([torch.Tensor(vec), zeros], dim=dim)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd_crSfOfo4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_collate(batch, values=(0, 0), dim=0):\n",
        "    \"\"\"\n",
        "    데이터 로더에 들어가기전에 batch화 할 때 거치는 함수 \n",
        "    args:\n",
        "        batch - list of (tensor, label)\n",
        "    reutrn:\n",
        "        xs - a tensor of all examples in 'batch' after padding\n",
        "        ys - a LongTensor of all labels in batch\n",
        "        ws - a tensor of sequence lengths\n",
        "    \"\"\"\n",
        "\n",
        "    sequence_lengths = torch.Tensor([int(x[0].shape[dim]) for x in batch]) # 각 batch 마다 길이를 얻어내고 \n",
        "    sequence_lengths, xids = sequence_lengths.sort(descending=True) # 감소하는 순서로 정렬\n",
        "    target_lengths = torch.Tensor([int(x[1].shape[dim]) for x in batch])\n",
        "    # find longest sequence (가장 긴 sequence의 길이를 구함 )\n",
        "    src_max_len = max(map(lambda x: x[0].shape[dim], batch))\n",
        "    tgt_max_len = max(map(lambda x: x[1].shape[dim], batch))\n",
        "    # pad according to max_len (max length 만큼 padd를 추가 )\n",
        "    batch = [(pad_tensor(x, pad=src_max_len, dim=dim), pad_tensor(y, pad=tgt_max_len, dim=dim)) for (x, y) in batch]\n",
        "\n",
        "    # stack all\n",
        "    xs = torch.stack([x[0] for x in batch], dim=0)\n",
        "    ys = torch.stack([x[1] for x in batch], dim=0)\n",
        "    xs = xs[xids].contiguous() # decreasing order로 다시 나열 \n",
        "    ys = ys[xids].contiguous() # xids 와 같은 순서로 \n",
        "    target_lengths = target_lengths[xids] \n",
        "    return xs.long(), ys.long(), sequence_lengths.int(), target_lengths.int()\n",
        "\n",
        "\n",
        "class ToyDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    https://talbaumel.github.io/blog/attention/\n",
        "    \"\"\"\n",
        "    def __init__(self, min_length=5, max_length=20, type='train'):\n",
        "        self.SOS = \"<s>\"  # all strings will end with the End Of String token )\n",
        "        self.EOS = \"</s>\"  # all strings will end with the End Of String token\n",
        "        self.characters = list(\"abcdefg\")\n",
        "        self.int2char = list(self.characters)\n",
        "        self.char2int = {c: i+3 for i, c in enumerate(self.characters)} # +3 을 왜하는 가?\n",
        "        print(self.char2int)\n",
        "        self.VOCAB_SIZE = len(self.characters)\n",
        "        self.min_length = min_length\n",
        "        self.max_length = max_length\n",
        "        \n",
        "        # train set or test set 을 생성 \n",
        "        if type == 'train':\n",
        "            self.set = [self._sample() for _ in range(4000)]\n",
        "        else:\n",
        "            self.set = [self._sample() for _ in range(300)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.set)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.set[item]\n",
        "\n",
        "    def _sample(self):\n",
        "        random_length = randrange(self.min_length, self.max_length)  # Pick a random length\n",
        "        random_char_list = [choice(self.characters[:-1]) for _ in range(random_length)]  # Pick random chars\n",
        "        random_string = ''.join(random_char_list)\n",
        "        a = np.array([self.char2int.get(x) for x in random_string]+[2])\n",
        "        b = np.array([self.char2int.get(x) for x in random_string[::-1]] + [2]) # Return the random string and its reverse + EOS \n",
        "        \n",
        "        return a, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMCn3O30fo4d",
        "colab_type": "text"
      },
      "source": [
        "### Attention Mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz2KbVrxfo4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 추후에 설명 Decoder section\n",
        "def mask_3d(inputs, seq_len, mask_value=0.):\n",
        "    batches = inputs.size()[0]\n",
        "    assert batches == len(seq_len) # length 체크 \n",
        "    max_idx = max(seq_len) # max length 체크 \n",
        "    for n, idx in enumerate(seq_len): # length 에서 의미없는 hidden state attention 값은 0으로 두기 위한 mask값 설정 \n",
        "        if idx < max_idx.item():\n",
        "            if len(inputs.size()) == 3:\n",
        "                inputs[n, idx.int():, :] = mask_value\n",
        "            else:\n",
        "                assert len(inputs.size()) == 2, \"The size of inputs must be 2 or 3, received {}\".format(inputs.size())\n",
        "                inputs[n, idx.int():] = mask_value\n",
        "    return inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_so-d9NHfo4k",
        "colab_type": "text"
      },
      "source": [
        "#### ENCODER RNN Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpE9WMlKfo4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.input_size = config[\"n_channels\"]\n",
        "        self.hidden_size = config[\"encoder_hidden\"]\n",
        "        self.layers = config.get(\"encoder_layers\", 1)\n",
        "        \n",
        "        self.dropout = config.get(\"encoder_dropout\", 0.) \n",
        "        self.bi = config.get(\"bidirectional_encoder\", False)\n",
        "        embedding_dim = config.get(\"embedding_dim\", None)\n",
        "        self.embedding_dim = embedding_dim if embedding_dim is not None else self.hidden_size\n",
        "        self.Embedding = nn.Embedding(config.get(\"vocab_size\", 32), self.embedding_dim, padding_idx=0)\n",
        "        gru_input_dim = self.embedding_dim\n",
        "        self.GRU = nn.GRU(\n",
        "            gru_input_dim,\n",
        "            self.hidden_size,\n",
        "            self.layers,\n",
        "            dropout=self.dropout,\n",
        "            bidirectional=self.bi,\n",
        "            batch_first=True)# model 선언 \n",
        "        self.gpu = config.get(\"gpu\", False) \n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, inputs, hidden, input_lengths):\n",
        "        ## (To do) 이 부분의 코드를 완성하시오! \n",
        "        #제공된 코드를 수정하지 않고 forward 문만 작성하여 코드를 구현해 주세요!\n",
        "        #기존 코드를 수정하지 않고 코드를 구현해 주세요!\n",
        "\n",
        "    def init_hidden(self, batch_size,config):\n",
        "        ## (To do) 이 부분의 코드를 완성하시오!\n",
        "        #제공된 코드의 다른 부분을 수정하지 않고 init_hidden 코드를 구현해 주세요!\n",
        "        #기존 코드를 수정하지 않고 코드를 구현해 주세요!\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIN4XoTpfo4p",
        "colab_type": "text"
      },
      "source": [
        "### Decoder "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jAFVW0Mfo4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_size = config[\"batch_size\"]\n",
        "        self.hidden_size = config[\"decoder_hidden\"]\n",
        "        embedding_dim = config.get(\"embedding_dim\", None)\n",
        "        self.embedding_dim = embedding_dim if embedding_dim is not None else self.hidden_size\n",
        "        self.Embedding = nn.Embedding(config.get(\"vocab_size\", 32), self.embedding_dim, padding_idx=0)\n",
        "        self.GRU = nn.GRU(\n",
        "            input_size=self.embedding_dim+self.hidden_size if config['decoder'].lower() == 'bahdanau' else self.embedding_dim,\n",
        "            hidden_size=self.hidden_size,\n",
        "            num_layers=config.get(\"decoder_layers\", 1),\n",
        "            dropout=config.get(\"decoder_dropout\", 0),\n",
        "            bidirectional=False,\n",
        "            batch_first=True)\n",
        "        if config['decoder'] != \"RNN\":\n",
        "            self.Attention = Attention(\n",
        "                self.batch_size,\n",
        "                self.hidden_size,\n",
        "                method=config.get(\"attention_score\", \"dot\"))\n",
        "\n",
        "        self.gpu = config.get(\"gpu\", False)\n",
        "        self.decoder_output_fn = F.log_softmax if config.get('loss', 'NLL') == 'NLL' else None\n",
        "\n",
        "    def forward(self, **kwargs):\n",
        "        \"\"\" Must be overrided \"\"\"\n",
        "        raise NotImplementedError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AC67suHfo4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        last_hidden: (batch_size, hidden_size)\n",
        "        encoder_outputs: (batch_size, max_time, hidden_size)\n",
        "    Returns:\n",
        "        attention_weights: (batch_size, max_time)\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_size, hidden_size, method=\"dot\"):\n",
        "        super(Attention, self).__init__()\n",
        "        self.method = method\n",
        "        self.hidden_size = hidden_size\n",
        "        if method == 'dot':\n",
        "            pass\n",
        "        elif method == 'general':\n",
        "            # Wa (hidden,hidden)\n",
        "            self.Wa = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "        elif method == \"concat\":\n",
        "            # Wa : (2*hidden,hidden)\n",
        "            # Va : (hidden,1)\n",
        "            self.Wa = nn.Linear(2*hidden_size, hidden_size, bias=False)\n",
        "            self.va = nn.Parameter(torch.FloatTensor(hidden_size, 1))\n",
        "        elif method == 'bahdanau':\n",
        "            # Wa : (hidden_size,hidden_size) \n",
        "            # Ua : (hidden_size,hidden_size)\n",
        "            # Va : (hidden_size,1)\n",
        "            self.Wa = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "            self.Ua = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "            self.va = nn.Parameter(torch.FloatTensor(hidden_size, 1))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        \n",
        "    def forward(self, last_hidden, encoder_outputs, seq_len=None):\n",
        "        \"\"\"\n",
        "        Inputs :\n",
        "          last_hidden : (B,T,hidden_size)\n",
        "          encoder_outputs : \n",
        "          seq_len:  \n",
        "        Returns:\n",
        "          attention matrix : \n",
        "        \"\"\"\n",
        "        batch_size, seq_lens, _ = encoder_outputs.size()\n",
        "        # attention energies 를 구하기 \n",
        "        attention_energies = self.score(last_hidden, encoder_outputs, self.method)\n",
        "        \n",
        "        if seq_len is not None:\n",
        "            attention_energies = mask_3d(attention_energies, seq_len, -float('inf'))\n",
        "\n",
        "        return F.softmax(attention_energies, -1)\n",
        "\n",
        "    def score(self, last_hidden, encoder_outputs, method):\n",
        "        # (To do) 코드를 완성하시오 \n",
        "        #기존 코드를 수정하지 않고 코드를 구현해 주세요!\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8EGCX8Qfo4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    \"\"\"\n",
        "        Sequence to sequence module\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.config = config\n",
        "        self.SOS = config.get(\"start_index\", 1) # Start index를 가져옵니다. \n",
        "        self.vocab_size = config.get(\"vocab_size\", 32) # embedding 에 필요한 vocabulary size \n",
        "        self.batch_size = config.get(\"batch_size\", 1) # batch_size 정보를 가져옵니다.\n",
        "        self.gpu = config.get(\"gpu\", False) # cuda 로 돌아가는지 아닌지에 대한 정보 \n",
        "\n",
        "        # Encoder 선언\n",
        "        \n",
        "        self.encoder = EncoderRNN(config)\n",
        "\n",
        "        # Decoder 선언 \n",
        "        \n",
        "        self.decoder = LoungDecoder(config)\n",
        "        \n",
        "        # loss fucntion \n",
        "        # ignore_index =0 왜???\n",
        "        self.loss_fn = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
        "        \n",
        "        \n",
        "\n",
        "    def encode(self, x, x_len):\n",
        "        # encoder를 통해 주어진 source 정보를 Encodeing 하는 용도 \n",
        "        \n",
        "        batch_size = x.size()[0]\n",
        "        # 초기 inital hidden state 만들기\n",
        "        init_state = self.encoder.init_hidden(batch_size,self.config)\n",
        "        # encoder Forward 수행 \n",
        "        encoder_outputs, encoder_state = self.encoder.forward(x, init_state, x_len)\n",
        "        \n",
        "        \n",
        "       \n",
        "        return encoder_outputs, encoder_state\n",
        "\n",
        "    def decode(self, encoder_outputs, encoder_hidden, targets, targets_lengths, input_lengths):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            encoder_outputs: (B, T, H)\n",
        "            encoder_hidden: (B, H)\n",
        "            targets: (B, L)\n",
        "            targets_lengths: (B)\n",
        "            input_lengths: (B)\n",
        "        Vars:\n",
        "            decoder_input: (B)\n",
        "            decoder_context: (B, H)\n",
        "            hidden_state: (B, H)\n",
        "            attention_weights: (B, T)\n",
        "        Outputs:\n",
        "            alignments: (L, T, B)\n",
        "            logits: (B*L, V)\n",
        "            labels: (B*L)\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = encoder_outputs.size()[0]\n",
        "        max_length = targets.size()[1]\n",
        "        # decoder의 처음 y0 는 무엇이 되어야 할까? *주의해야할 포인트 \n",
        "        if batch_size ==1:\n",
        "          decoder_input = torch.LongTensor([self.SOS] * batch_size)\n",
        "        else:\n",
        "          decoder_input = torch.LongTensor([self.SOS] * batch_size).squeeze(-1)\n",
        "        decoder_context = encoder_outputs.transpose(1, 0)[-1] #(Batch,1)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        #alignments :  attention align을 저장하기 위한 용도  \n",
        "        alignments = torch.zeros(max_length, encoder_outputs.size(1), batch_size) # attention align을 저장하기 위한 용도 \n",
        "        logits = torch.zeros(max_length, batch_size, self.decoder.output_size) # logits 값을 저장하기 위한 용도의 tensor \n",
        "\n",
        "        if self.gpu:\n",
        "            decoder_input = decoder_input.cuda()\n",
        "            decoder_context = decoder_context.cuda()\n",
        "            logits = logits.cuda()\n",
        "        inference = []\n",
        "        for t in range(max_length):\n",
        "\n",
        "            # The decoder accepts, at each time step t :\n",
        "            # - an input, [B]\n",
        "            # - a context, [B, H]\n",
        "            # - an hidden state, [B, H]\n",
        "            # - encoder outputs, [B, T, H]\n",
        "            \n",
        "            # The decoder outputs, at each time step t :\n",
        "            # - an output, [B]\n",
        "            # - a context, [B, H]\n",
        "            # - an hidden state, [B, H]\n",
        "            # - weights, [B, T]\n",
        "\n",
        "            outputs, decoder_hidden, attention_weights = self.decoder.forward(\n",
        "                    input=decoder_input.long(),\n",
        "                    last_hidden=decoder_hidden,\n",
        "                    Encoder_Outputs=encoder_outputs,\n",
        "                    Seq_Len=input_lengths)\n",
        "            \n",
        "            alignments[t] = attention_weights.transpose(1, 0)\n",
        "            \n",
        "            \n",
        "            logits[t] = outputs\n",
        "\n",
        "            \n",
        "\n",
        "            if  self.training:\n",
        "                decoder_input = targets[:, t]\n",
        "            else:\n",
        "                topv, topi = outputs.data.topk(1) # 가장 높은 예측만 사용.\n",
        "                decoder_input = topi.squeeze(-1).detach()\n",
        "                inference.append(decoder_input.cpu())\n",
        "\n",
        "        \n",
        "        labels = targets.contiguous().view(-1)\n",
        "\n",
        "        \n",
        "        mask_value = 0\n",
        "        #what is this mask_3d? # (warning check)\n",
        "        logits = mask_3d(logits.transpose(1, 0), targets_lengths, mask_value)\n",
        "        logits = logits.contiguous().view(-1, self.vocab_size) # loss를 구하기 위해 쫙 펴주기 \n",
        "\n",
        "        return logits, labels.long(), alignments,inference\n",
        "\n",
        "    \n",
        "    def step(self, batch):\n",
        "        x, y, x_len, y_len = batch\n",
        "        if self.gpu:\n",
        "            x = x.cuda()\n",
        "            y = y.cuda()\n",
        "            x_len = x_len.cuda()\n",
        "            y_len = y_len.cuda()\n",
        "\n",
        "        encoder_out, encoder_state = self.encode(x, x_len) # encoder \n",
        "        logits, labels, alignments,inference = self.decode(encoder_out, encoder_state, y, y_len, x_len) # decoder 를 통해 alignment와 logit 값 얻기 \n",
        "        return logits, labels, alignments,inference\n",
        "\n",
        "    def loss(self, batch):\n",
        "        logits, labels, alignments,inference = self.step(batch)\n",
        "        loss = self.loss_fn(logits, labels) # loss 구하기 우리는 cross entropy 사용 \n",
        "        return loss, logits, labels, alignments,inference"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0UVg52Mfo43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LoungDecoder(Decoder):\n",
        "    \"\"\"\n",
        "        Corresponds to LoungAttnDecoderRNN \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(LoungDecoder, self).__init__(config)\n",
        "        self.output_size = config.get(\"vocab_size\", 32)\n",
        "        self.outputs2vocab = nn.Linear(self.hidden_size*2, self.output_size)\n",
        "        \n",
        "    def forward(self, **kwargs):\n",
        "\n",
        "        #기존 코드를 수정하지 않고 코드를 구현해 주세요!\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs1Mfjrbfo47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, train_loader, epoch,n_epochs):\n",
        "    \n",
        "\n",
        "    losses = []\n",
        "    cers = []\n",
        "\n",
        "    \n",
        "    model.train() # train mode \n",
        "    count = 0\n",
        "    n_iter = 0\n",
        "    for batch in train_loader:\n",
        "        loss, _, _, _,_ = model.loss(batch)\n",
        "        losses.append(loss.item())\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Compute gradients\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        n_iter+=1 # count number of iteration\n",
        "        if n_iter % 10 == 0: # print loss only if it's training stage\n",
        "            print ('\\n [{}] current_iter_loss= {:05.3f}'.format(n_iter,loss))\n",
        "  \n",
        "    print ('\\n [{}/{}] avg_loss= {:05.3f}'.format(epoch,n_epochs,np.mean(losses)))\n",
        "    \n",
        "    return model, optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVDeLpOyfo4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, eval_loader):\n",
        "\n",
        "    losses = []\n",
        "    accs = []\n",
        "    edits = []\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in eval_loader:\n",
        "            #t.set_description(\" Evaluating... (train={})\".format(model.training))\n",
        "            loss, logits, labels, alignments,_ = model.loss(batch)\n",
        "            preds = logits.detach().cpu().numpy()\n",
        "            \n",
        "            acc = 100 *np.sum(np.argmax(preds, -1) == labels.detach().cpu().numpy()) / len(preds)\n",
        "            edit = editdistance.eval(np.argmax(preds, -1), labels.detach().cpu().numpy()) / len(preds)\n",
        "            \n",
        "            losses.append(loss.item())\n",
        "            \n",
        "            accs.append(acc)\n",
        "            edits.append(edit)\n",
        "        \n",
        "        align = alignments.detach().cpu().numpy()[:, :, 0]\n",
        "\n",
        "   \n",
        "    print(\"  End of evaluation : loss {:05.3f} , acc {:03.1f} , edits {:03.3f}\".format(np.mean(losses), np.mean(accs), np.mean(edits)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV5mnJ7mfo5B",
        "colab_type": "code",
        "colab": {},
        "outputId": "497e8967-d5dd-4578-b440-991abce302cd"
      },
      "source": [
        "# 물음표를 채워 주세요!!\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "batch_size = 32\n",
        "epochs = ???\n",
        "\n",
        "dataset = ToyDataset(5, 15)\n",
        "eval_dataset = ToyDataset(5, 15, type='eval')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9}\n",
            "{'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7skNIiAfo5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate, drop_last=True)\n",
        "eval_loader = data.DataLoader(eval_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate,drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gccW1BXafo5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 물음표를 채워 주세요!!\n",
        "config = {\n",
        "  \"decoder\": \"Loung\",\n",
        "  \"encoder\": \"RNN\",\n",
        "  \"n_channels\": 4,\n",
        "  \"encoder_hidden\": ???,\n",
        "  \"encoder_layers\": 2,\n",
        "  \"encoder_dropout\": 0.1,\n",
        "  \"bidirectional_encoder\": True,\n",
        "  \"decoder_hidden\": ???,\n",
        "  \"decoder_layers\": 2,\n",
        "  \"decoder_dropout\": 0.1,\n",
        "  \"vocab_size\":??? , # TopyDataset 의 vocab 사이즈는 Encoder, Decoder 구분없이 같음\n",
        "  \"batch_size\": 32,\n",
        "  \"embedding_dim\": ???,\n",
        "  \"attention_score\": ???,\n",
        "  \"learning_rate\": 0.001,\n",
        "  \"gpu\": True,\n",
        "  \"loss\": \"cross_entropy\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL5JBTqgfo5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Seq2Seq(config)\n",
        "model = model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BL5SdlZfo5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=config.get(\"learning_rate\", .001))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPezA6Zsfo5M",
        "colab_type": "code",
        "colab": {},
        "outputId": "dfbd47bf-0ad1-47cc-8274-b5219ec3b813"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  model,optimizer  = train(model,optimizer, train_loader,epoch,epochs)\n",
        "  evaluate(model,eval_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " [10] current_iter_loss= 1.921\n",
            "\n",
            " [20] current_iter_loss= 1.748\n",
            "\n",
            " [30] current_iter_loss= 1.545\n",
            "\n",
            " [40] current_iter_loss= 1.374\n",
            "\n",
            " [50] current_iter_loss= 1.229\n",
            "\n",
            " [60] current_iter_loss= 1.036\n",
            "\n",
            " [70] current_iter_loss= 0.826\n",
            "\n",
            " [80] current_iter_loss= 0.743\n",
            "\n",
            " [90] current_iter_loss= 0.557\n",
            "\n",
            " [100] current_iter_loss= 0.488\n",
            "\n",
            " [110] current_iter_loss= 0.439\n",
            "\n",
            " [120] current_iter_loss= 0.372\n",
            "\n",
            " [0/5] avg_loss= 1.071\n",
            "  End of evaluation : loss 0.438 , acc 89.2 , edits 0.083\n",
            "\n",
            " [10] current_iter_loss= 0.264\n",
            "\n",
            " [20] current_iter_loss= 0.265\n",
            "\n",
            " [30] current_iter_loss= 0.262\n",
            "\n",
            " [40] current_iter_loss= 0.277\n",
            "\n",
            " [50] current_iter_loss= 0.232\n",
            "\n",
            " [60] current_iter_loss= 0.180\n",
            "\n",
            " [70] current_iter_loss= 0.207\n",
            "\n",
            " [80] current_iter_loss= 0.164\n",
            "\n",
            " [90] current_iter_loss= 0.146\n",
            "\n",
            " [100] current_iter_loss= 0.164\n",
            "\n",
            " [110] current_iter_loss= 0.181\n",
            "\n",
            " [120] current_iter_loss= 0.123\n",
            "\n",
            " [1/5] avg_loss= 0.209\n",
            "  End of evaluation : loss 0.124 , acc 98.1 , edits 0.018\n",
            "\n",
            " [10] current_iter_loss= 0.136\n",
            "\n",
            " [20] current_iter_loss= 0.131\n",
            "\n",
            " [30] current_iter_loss= 0.109\n",
            "\n",
            " [40] current_iter_loss= 0.118\n",
            "\n",
            " [50] current_iter_loss= 0.112\n",
            "\n",
            " [60] current_iter_loss= 0.099\n",
            "\n",
            " [70] current_iter_loss= 0.122\n",
            "\n",
            " [80] current_iter_loss= 0.100\n",
            "\n",
            " [90] current_iter_loss= 0.131\n",
            "\n",
            " [100] current_iter_loss= 0.115\n",
            "\n",
            " [110] current_iter_loss= 0.144\n",
            "\n",
            " [120] current_iter_loss= 0.089\n",
            "\n",
            " [2/5] avg_loss= 0.109\n",
            "  End of evaluation : loss 0.224 , acc 97.1 , edits 0.017\n",
            "\n",
            " [10] current_iter_loss= 0.128\n",
            "\n",
            " [20] current_iter_loss= 0.098\n",
            "\n",
            " [30] current_iter_loss= 0.080\n",
            "\n",
            " [40] current_iter_loss= 0.065\n",
            "\n",
            " [50] current_iter_loss= 0.073\n",
            "\n",
            " [60] current_iter_loss= 0.073\n",
            "\n",
            " [70] current_iter_loss= 0.076\n",
            "\n",
            " [80] current_iter_loss= 0.102\n",
            "\n",
            " [90] current_iter_loss= 0.084\n",
            "\n",
            " [100] current_iter_loss= 0.071\n",
            "\n",
            " [110] current_iter_loss= 0.048\n",
            "\n",
            " [120] current_iter_loss= 0.075\n",
            "\n",
            " [3/5] avg_loss= 0.084\n",
            "  End of evaluation : loss 0.068 , acc 99.4 , edits 0.005\n",
            "\n",
            " [10] current_iter_loss= 0.053\n",
            "\n",
            " [20] current_iter_loss= 0.054\n",
            "\n",
            " [30] current_iter_loss= 0.067\n",
            "\n",
            " [40] current_iter_loss= 0.069\n",
            "\n",
            " [50] current_iter_loss= 0.064\n",
            "\n",
            " [60] current_iter_loss= 0.047\n",
            "\n",
            " [70] current_iter_loss= 0.050\n",
            "\n",
            " [80] current_iter_loss= 0.043\n",
            "\n",
            " [90] current_iter_loss= 0.059\n",
            "\n",
            " [100] current_iter_loss= 0.057\n",
            "\n",
            " [110] current_iter_loss= 0.038\n",
            "\n",
            " [120] current_iter_loss= 0.041\n",
            "\n",
            " [4/5] avg_loss= 0.059\n",
            "  End of evaluation : loss 0.064 , acc 99.3 , edits 0.006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRDH1s6zfo5O",
        "colab_type": "text"
      },
      "source": [
        "### 모델제출 - 학습된 모델 저장 및 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9AelOtyfo5P",
        "colab_type": "code",
        "colab": {},
        "outputId": "695448f2-c248-4f6e-e1ee-e0dd471edfd2"
      },
      "source": [
        "# 모델 저장 - (./trained_model + ./config.pkl) 제출\n",
        "pickle.dump(config, open(\"./config.pkl\", \"wb\" ))\n",
        "torch.save(model.state_dict(), \"./trained_model\")\n",
        "# 저장된 모델 확인하기\n",
        "if os.path.isfile(\"./config.pkl\"):\n",
        "    with open(\"./config.pkl\",\"rb\") as f:\n",
        "        config = pickle.load(f)\n",
        "model = Seq2Seq(config).cuda()\n",
        "model.load_state_dict(torch.load(\"./trained_model\"))\n",
        "model.eval()\n",
        "evaluate(model,eval_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  End of evaluation : loss 0.064 , acc 99.3 , edits 0.006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPjWopG0fo5Q",
        "colab_type": "text"
      },
      "source": [
        "### 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS7JT4GOfo5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn\n",
        "\n",
        "def draw(data, x, y):\n",
        "    seaborn.heatmap(data, \n",
        "                    xticklabels=x, square=True, yticklabels=y, vmin=0.0, vmax=1.0, \n",
        "                    cbar=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNBMYbL5fo5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_plot(model,custom_input= 'cgdafa'):\n",
        "    c_xs = np.array([dataset.char2int.get(x) for x in custom_input]+[2])\n",
        "    c_xs = torch.from_numpy(c_xs).unsqueeze(0).long()\n",
        "\n",
        "    c_xl = torch.tensor(c_xs[0].size()[-1]).unsqueeze(0)\n",
        "\n",
        "    c_ys = np.array([dataset.char2int.get(x) for x in custom_input[::-1]] + [2]) # Return the random string and its reverse + EOS \n",
        "    c_ys = torch.from_numpy(c_ys).unsqueeze(0).long()\n",
        "\n",
        "    c_yl = torch.tensor(c_ys[0].size()[-1]).unsqueeze(0)\n",
        "    c_data = (c_xs,c_ys,c_xl,c_yl)\n",
        "    loss, logits, labels, alignments,predict=model.loss(c_data)\n",
        "    heat_map_value = alignments.detach().cpu().numpy()[:, :, 0]\n",
        "    preds = logits.detach().cpu().numpy()\n",
        "    preds = np.argmax(preds, -1)\n",
        "    source_tokens = [ dataset.int2char[item-3] for item in c_xs[0] if item!=0 if item !=2 ] +['</s>']\n",
        "    target_tokens = [ dataset.int2char[item-3] if item !=2 else '</s>' for item in preds.tolist() if item!=0 ]\n",
        "    draw(heat_map_value,source_tokens,target_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y627Dwfpfo5e",
        "colab_type": "code",
        "colab": {},
        "outputId": "f4efeb04-84e7-457f-b692-0c95855be928"
      },
      "source": [
        "visualize_plot(model,'cbada')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueLGyyENfo5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}